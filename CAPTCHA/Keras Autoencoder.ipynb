{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Imports](#Imports)\n",
    "3. [Data Processing](#Data-Processing) <br>\n",
    "3.1 [Normalization](#Normalization) <br>\n",
    "3.2 [Categorization](#Categorization) <br>\n",
    "3.3 [Train-test Split](#Train-test-Split) <br>\n",
    "3.4 [Data Augmentation](#Data-Augmentation) <br>\n",
    "4. [Convolutional Autoencoder](#Convolutional-Autoencoder)  <br>\n",
    "4.1 [Visualise Reconstructed Images](#Visualise-Reconstructed-Images) <br>\n",
    "4.2 [Salt and Peper Noise](#Salt-and-Peper-Noise) <br>\n",
    "4.3 [Visualise Denoised Images](#Visualise-Denoised-Images) <br>\n",
    "3.3 [Train-test Split](#Train-test-Split) <br>\n",
    "5. [Categorization Neural Network](#Categorization-Neural-Network) <br>\n",
    "5.1 [Train-test Split](#Train-test-Split) <br>\n",
    "5.2 [Data Augmentation](#Data-Augmentation) <br>\n",
    "5.3 [Model](#Model) <br>\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook is an attempt at solving a CAPTCHA test.\n",
    "This CAPTCHA is an 5 letter with noise (a blur and line that crosses the word).\n",
    "I approcahed the problem by initially segmenting the word using OpenCV (see the notebook). This mainly enables to remove the blur and reduce the width of the line. <br>\n",
    "Since this is not enough, to have a reliable prediction of the word, I explored autoencoders using Keras with a Tensorflow backend. Autoencoders are very simply two Neural Networks plugged to each other: the encoder reduces the dimensions of the data (compressing it) and the decoder expands the dimensions (decompressing/reconstructing it). Thus they are very good at denoising data. Since the images are not clear yet, using an autoencoder is ideal for further data cleaning. So I chose for each letter the most (humanly) readable letter and trained the AE on reconstructing these ideal letters.<br>\n",
    "Because the CAPTCHA dataset is very small, I used Data Augmentation to enlarge it. Autoencoders are data specific, this means given very different data it will not perform well, so I will add salt and pepper noise to the data and retrain our model. <br>\n",
    "At this point our model is able to denoise varied CAPTCHA Images so I use the Encoder Neural Network to predict the label of the letter and decipher the word.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from imutils import paths\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, Dense, Dropout, Input, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "import keras.optimizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n",
    "Load the CAPTCHA images, the target images and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in paths.list_images(LETTER_FOLDER):\n",
    "    # Load the image.\n",
    "    image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Add a third channel dimension to the image.\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "\n",
    "    # Get the folder name (ie. the true character value).\n",
    "    label = image_file.split(os.path.sep)[-2]\n",
    "\n",
    "    # Add the image and char to the dictionary.\n",
    "    data.append(image)\n",
    "    if label == '2':\n",
    "        img = cv2.imread('letters/2/000005.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(1)\n",
    "    elif label == '3':\n",
    "        img = cv2.imread('letters/3/000127.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(2)\n",
    "    elif label == '4':\n",
    "        img = cv2.imread('letters/4/000001.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(3)\n",
    "    elif label == '5':\n",
    "        img = cv2.imread('letters/5/000007.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(4)\n",
    "    elif label == '6':\n",
    "        img = cv2.imread('letters/6/000006.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(5)\n",
    "    elif label == '7':\n",
    "        img = cv2.imread('letters/7/000017.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(6)\n",
    "    elif label == '8':\n",
    "        img = cv2.imread('letters/8/000004.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(7)\n",
    "    elif label == 'b':\n",
    "        img = cv2.imread('letters/b/000001.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(8)\n",
    "    elif label == 'c':\n",
    "        img = cv2.imread('letters/c/000014.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(9)\n",
    "    elif label == 'd':\n",
    "        img = cv2.imread('letters/d/000025.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(10)\n",
    "    elif label == 'e':\n",
    "        img = cv2.imread('letters/e/000004.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(11)\n",
    "    elif label == 'f':\n",
    "        img = cv2.imread('letters/f/000015.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(12)\n",
    "    elif label == 'g':\n",
    "        img = cv2.imread('letters/g/000034.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(13)\n",
    "    elif label == 'm':\n",
    "        img = cv2.imread('letters/m/000036.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(14)\n",
    "    elif label == 'n':\n",
    "        img = cv2.imread('letters/n/000002.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(15)\n",
    "    elif label == 'p':\n",
    "        img = cv2.imread('letters/p/000002.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(16)\n",
    "    elif label == 'w':\n",
    "        img = cv2.imread('letters/w/000017.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(17)\n",
    "    elif label == 'x':\n",
    "        img = cv2.imread('letters/x/000012.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(18)\n",
    "    elif label == 'y':\n",
    "        img = cv2.imread('letters/y/000014.png', cv2.IMREAD_GRAYSCALE)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        target.append(img)\n",
    "        labels.append(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "target = np.array(target, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(labels, num_classes=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_test, y_train, y_test) = train_test_split(data, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(# randomly rotate images in the range (degrees, 0 to 180).\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1,  # Randomly zoom image.\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of total width).\n",
    "    height_shift_range=0.1, # randomly shift images vertically (fraction of total height).\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder\n",
    "\n",
    "The data is 2D images so we use Convolutional and MaxPooling/UpSampling Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(40, 24, 1))\n",
    "\n",
    "# Encoder.\n",
    "x = Conv2D(16, (5, 5), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (5, 5), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (5, 5), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# Decoder.\n",
    "x = Conv2D(8, (5, 5), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (5, 5), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (5, 5), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (5, 5), activation='sigmoid', padding='same')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer.\n",
    "optimizer = keras.optimizers.Adam(\n",
    "    lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "# Callbacks.\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_acc', patience=2, verbose=1, factor=0.4, min_lr=0.000001)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "\n",
    "# Create model.\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer=optimizer,\n",
    "                    loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = autoencoder.fit_generator(datagen.flow(x_train, y_train, batch_size=64),\n",
    "                                    # history = autoencoder.fit(x_train, y_train, batch_size=64,\n",
    "                                    epochs=1, validation_data=(x_test, y_test),\n",
    "                                    verbose=1, steps_per_epoch=x_train.shape[0],\n",
    "                                    callbacks=[learning_rate_reduction, early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Reconstructed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "n = 5\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    i = i + 1\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(40, 24))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(40, 24))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salt and Peper Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * \\\n",
    "    np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * \\\n",
    "    np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model.\n",
    "history = autoencoder.fit_generator(datagen.flow(x_train, y_train, batch_size=64),\n",
    "                                    # history = autoencoder.fit(x_train_noisy, y_train, batch_size=64,\n",
    "                                    epochs=1, validation_data=(x_test_noisy, y_test),\n",
    "                                    verbose=1, steps_per_epoch=x_train.shape[0],\n",
    "                                    callbacks=[learning_rate_reduction, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Denoised Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "n = 5\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    i = i + 1\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test_noisy[i].reshape(40, 24))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(40, 24))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorization Neural Network\n",
    "\n",
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use denoise images.\n",
    "decoded_images = autoencoder.predict(data)\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(\n",
    "    decoded_images, labels, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator( # randomly rotate images in the range (degrees, 0 to 180).\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1, # Randomly zoom image.\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of total width).\n",
    "    height_shift_range=0.1, # randomly shift images vertically (fraction of total height).\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model for labelling images.\n",
    "out = Flatten()(encoder.output)\n",
    "out = Dense(19, activation='softmax')(out)\n",
    "labeller = Model(encoder.input, out)\n",
    "\n",
    "labeller.compile(optimizer=optimizer,\n",
    "                 loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = labeller.fit_generator(datagen.flow(x_train, y_train, batch_size=64),\n",
    "                                 # history = labeller.fit(x_train, y_train, batch_size=64,\n",
    "                                 epochs=1, validation_data=(x_test, y_test),\n",
    "                                 verbose=1, steps_per_epoch=x_train.shape[0],\n",
    "                                 callbacks=[learning_rate_reduction, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = labeller.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Accuracy: \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
